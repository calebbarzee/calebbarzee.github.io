---
title: "Generative AI: the good, the bad, and the ugly"
subtitle: "Opinions after 1 year of using generative AI."
date_written: "2023-10-23"
---
<!-- Metadata for title, subtitle, date written, tags -->
<!-- tags: ["ai","chatGPT","LLM","NLP","Natural Language Processing", "Large Language Models"] -->

## Why does this article exist?

I’ve been using generative ai for about 6 months now, and I am both surprised by and eager to share my findings. There has been a huge amount of hype associated with generative ai, some of it warranted. I’ve encountered a wide range of ai experiences, each experience informing me of best practices and pitfalls. I wanted to share these insights with you because I’ve noticed an improvement in my workflow and I think it could help you too. The big problem is a lack of overall understanding and experience in utilizing these tools. That is what this article aims to solve.

## What is generative ai?

Generative ai = generative artificial intelligence. This name is both informing and misleading. I think a more useful name might be generative content prediction models. I want to open up the black box that is ai tooling and allow you to peer inside. First most ai is simply a massive math problem. I like to think of it as a large statistical model that can view input, tag that input, interpret those tags in a larger set to then predict a response. If this seemed vague, then maybe look at specific models of generative ai and explore those with this larger picture in mind.

## Why should I care about generative ai?

The capabilities of these models to mimic human behavior in predicting output will most likely dramatically effect everyday life. I’ve already increased the speed and accuracy of many common tasks with generative ai. It’s likely that these models will only continue to get better, so it’s wise to adopt early and become familiar with tooling that may become ubiquitous.

## The good
###### Optimal use cases and things the technology is particularly good at

- common knowledge fact reference
    - I’ve replaced almost all web search engine requests for encyclopedia like information with chatGPT due to it’s NLP response alleviating cognitive load.
- typo detection
    - Machines are much better at repetitive tasks than humans. I’ve found that generative ai can actually proof read large amounts of text quickly and semi effectively. My preferred process is asking it to point out the mistakes instead of generating the corrected text. I find that maintaining current state and then being able to choose myself which corrections to implement leads to best results and eliminates unwanted changes.
- text formatting
    - Another example of the type of repetitive task that predictive ai models live for.
- iterative ideation
    - This is like asking a coworker what they think and their input improving your original thought. In essence this is combining your unique ideas with a rich resource of information. See conclusion for additional details.
- broad scope information
    - I will not be reading all classic literary works in my lifetime. I simply do not have the time or desire to. However, I could train an ai model on this incredible set of texts and then query it for information. I love using ai models to learn something new from resources I might have never encountered.

## The bad
###### Non-optimal use cases of generative ai

- new context interpretation without retraining
    - I challenge you to try and teach an english LLM to reliably respell the english language based on phonetic rules. I don’t think it’s possible without a complete retraining of the model. This new context will not be included in the models processing of information. Remember this is just a statistical structure modeling behavior, not a thinking machine.
- highly opinionated or uncommon reference
    - If there are multiple differing opinions on a topic, there isn’t a reliable way of determining the best opinion. Usually what happens is the opinion that occurs the most is adopted. Please think for yourself.
- complex cause and effect mechanics
    - With a generative ai model there isn’t native support for multi-step logic problems. This means that cause and effect predictions can be quite poor. It’s best to reason through this vertical slice yourself. Those individuals like myself that write code for a living, would benefit from knowing that generative ai will not write a good or even functional code base for you. This is increasingly true with each layer of complexity involved.

## The ugly
###### The worst and regressive things that are happening due to generative ai

- outsourcing of all frontal lobe functions
    - We will still need educators, writers, engineers, doctors, etc. Ai does not and will not replace human thought. If you are a student, and I hope everyone considers themselves one, do not expect to learn without effort.
- repetition of common misconceptions
    - What if a geocentric model or flat earth theory was widely accepted as fact today and not yet known commonly to be false. Our data sets for training predictive ai models would certainly contain this information. It would then be spewed as fact by all instances of the ai. This example may seem extreme, but whats truly dangerous is that things similar to this are happening now and we may not even know it. If we turn off our brains these untrue assumptions are sure to run rampant.
- current event interpretation
    - I do not expect generative ai to have a “good take” on the current Israel and Palestine conflict. Neither should you. There have been multiple horrific examples of ai gone awry when unsupervised with contemporary data.
- guide rails and self censorship
    - I thank the ingenuity and dedication of antagonistic individuals in depicting the swiss cheese fence that is generative ai rule sets.
- hallucinations
    - Rare, bizarre, entertaining, but potentially dangerous nonetheless.

## Beautifying the ugly

### Think more, not less

The ai does not think. Do not stop thinking. It is a tool not a person. The human brain is yet to be duplicated in digital form, and even if it was your unique experience and thought process is of value.

That said, when the robot overlords take over I hope they favor me due to my continued use of please, thank you, and praise in my ai prompting.

### Better data = better results

The biggest pitfall of all generative ai is data contamination. This includes data that we think is correct today, but is later discovered to be incorrect. You simply cannot expect a model to predict accurately thus giving accurate information, when it was trained on inaccurate information. There is just no way for the model to self correct.

### Opinions & ai don’t mix

We should most definitely limit the applications of generative ai. It’s that simple. One of the smartest things openAI ever did was to not give chatGPT knowledge of contemporary events. 

As the technology has been progressing the temptation has continually been to give access to the newest information. This is a mistake. As previously stated, we must train models on accurate data.

### We can’t change or control the model once it’s built

I once met a mother with a child who has a disability. At the Special Olympics, she noticed individuals diagnosed with Tourette's syndrome, raised in strict religious environments, didn't utter expletives, while others did. She inferred they hadn’t been exposed to such language.

Generative ai is similar, its output reflects its training data. we can’t expect a preliminary prompt to prevent the model from outputting data that it was trained on. This is why the original data set is so important.

### When hallucinating ask a buddy

Hallucinations are more rare, and we can make them almost non-existent through multiple checks. Hypothetically, if you were tripping on LSD, it would help to have a trusted friend around to refer to when things get wacky.

## Conclusion: the key is interactivity

You may have already come to the same conclusion. Regardless, my case for interactivity being the core feature of utilizing ai is as follows:

computer computes, not thinks →

ai model computes, not thinks →

human thinks →

computer + human = efficient thinking with computation →

computer (no human) = brick →

ai models + humans = efficient thinking with computation.

### The next chapter

As ai tooling continues to develop I hope we see diverse and more specialized tools developed. Much like how photography showed us what painting is and isn’t, ai will help us discover what it means to be human.

---


**post script rant:** 

Verbose writing, while increasingly easier to generate with ai, will continue to be useless.